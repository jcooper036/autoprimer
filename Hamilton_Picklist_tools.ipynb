{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for processing platelet picklists to Hamilton genotyping picklists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "import cauldron_sdk as api\n",
    "from Genotyping_picklist import make_picklist\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input, tweak next cell as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path is the location of the picklists\n",
    "# picklist_files are the platelet picklist files\n",
    "path = '../CRISPR_genotyping/IB-GP-E3-H/'\n",
    "picklist_files = ['IB-GP-E3-H-B1_IB-PG-E1-H-B3_guide_picklist.csv',\n",
    "                  'IB-GP-E3-H-B2_IB-GP-E2-H-B3_guide_picklist.csv',\n",
    "                  'IB-GP-E3-H-B3_guide_picklist.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {'_'.join(i.split('_')[:-1]):{'picklist_file':os.path.join(path,i)} for i in picklist_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in experiments:\n",
    "    exp_dir = os.path.join(path,experiment)\n",
    "    if not os.path.isdir(exp_dir): os.mkdir(exp_dir)\n",
    "    experiments[experiment]['directory'] = exp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and variables for turning platelet picklists into 2d maps and Hamilton picklists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCR_suffix = '_hamilton_PCR_picklist.csv'\n",
    "seq_suffix = '_hamilton_seq_picklist.csv'\n",
    "\n",
    "def add_row_col(long_skinny):\n",
    "    # df, reads the 'Destination Well' field and adds row and column fields from that\n",
    "    rows = []\n",
    "    cols = []\n",
    "    for i,line in long_skinny.iterrows():\n",
    "        well = line['Destination Well']\n",
    "        match = re.match(r\"([a-z]+)([0-9]+)\", well, re.I)\n",
    "        row,col = match.groups()\n",
    "        rows.append(row)\n",
    "        cols.append(int(col))\n",
    "    long_skinny['row'] = rows\n",
    "    long_skinny['column'] = cols\n",
    "    return\n",
    "\n",
    "def build_outmaps(experiments):\n",
    "    # takes a list of dfs and builds a dict of 2D dfs of the individual quadrants\n",
    "    # Blank 384 well plate\n",
    "    r = list(string.ascii_uppercase)[:16]\n",
    "    c = [i for i in range(1,25)]\n",
    "    blank_plate = pd.DataFrame(columns = c, index = r)   \n",
    "    old_column_names = list(range(13,25))\n",
    "    COL_RENAME = {}\n",
    "    for i,j in zip(c, old_column_names):\n",
    "        COL_RENAME[j]=i\n",
    "    old_row_names = list(string.ascii_uppercase)[8:16]\n",
    "    ROW_RENAME = {}\n",
    "    for i,j in zip(old_row_names, r):\n",
    "        ROW_RENAME[i] = j\n",
    "\n",
    "    for experiment in experiments:\n",
    "        picklist = experiments[experiment]['picklist']\n",
    "        plates = picklist.Destination.unique()\n",
    "        PLATES = {}\n",
    "        for plate in plates:\n",
    "            QUADS = {}\n",
    "            platemap = blank_plate.copy()\n",
    "            temp_df = picklist[picklist['Destination'] == plate]\n",
    "            for idx,line in temp_df.iterrows():\n",
    "                row = line['row']\n",
    "                column = line['column']\n",
    "                rec = line['REC ID']\n",
    "                platemap.loc[row,column] = rec\n",
    "            Q1 = platemap.iloc[:8,:12]\n",
    "            Q2 = platemap.iloc[:8,12:]\n",
    "            Q3 = platemap.iloc[8:,:12]\n",
    "            Q4 = platemap.iloc[8:,12:]\n",
    "            Q2.rename(columns = COL_RENAME, inplace = True)\n",
    "            Q3.rename(index = ROW_RENAME, inplace = True)\n",
    "            Q4.rename(index = ROW_RENAME, columns = COL_RENAME, inplace = True)\n",
    "            for i, j in zip(['Q1','Q2','Q3','Q4'],[Q1,Q2,Q3,Q4]):\n",
    "                if not j.dropna().empty: QUADS[i]=j   \n",
    "            MAPS = {'quad_maps':QUADS}    \n",
    "            PLATES[plate] = MAPS   \n",
    "        experiments[experiment]['plates'] = PLATES\n",
    "    return\n",
    "\n",
    "def platelet_to_dict(experiments):\n",
    "    # Takes a lists of platelet csv files and creates a list of DFs with the pertinent information\n",
    "    fields = ['Destination','Destination Well','REC ID']\n",
    "    for experiment in experiments:\n",
    "        data_file = experiments[experiment]['picklist_file']\n",
    "        temp = pd.read_csv(data_file)\n",
    "        temp = temp[fields]\n",
    "        add_row_col(temp)\n",
    "        experiments[experiment]['picklist'] = temp\n",
    "    return\n",
    "\n",
    "def write_maps(experiments):\n",
    "    engine = 'xlsxwriter'  # must have installed\n",
    "    for experiment in experiments:\n",
    "        for plate in experiments[experiment]['plates']:\n",
    "            out_file = f'{plate}_map.xlsx'\n",
    "            out_dir = experiments[experiment]['directory']\n",
    "            with pd.ExcelWriter(os.path.join(out_dir,out_file), engine=engine) as writer:\n",
    "                for i in experiments[experiment]['plates'][plate]['quad_maps']:\n",
    "                    experiments[experiment]['plates'][plate]['quad_maps'][i].to_excel(writer, sheet_name=i)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the picklists and reformat to 2D quadrant maps. Save the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "platelet_to_dict(experiments)\n",
    "build_outmaps(experiments)\n",
    "write_maps(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to interact with the gSheet \"HTS Primer Master List\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE -change paths in get_creds to reference autoprimer primary directory\n",
    "PRIMER_MASTERLIST_SPREADSHEET_ID = '1l2F7wasrVrYSHFIfX0sN2SFkzFz46CCHJfIBXb5R0n4'\n",
    "PRIMERS_SHEETNAME = 'Primers'\n",
    "PRIMER_MIXES_SHEETNAME = 'PM and sample name'\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "\n",
    "def fetch_data(spreadsheet_id, sheet, data_range):\n",
    "    creds = get_creds()\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    sheet_range_str = f'{sheet}!{data_range}'\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=spreadsheet_id,\n",
    "                                range=sheet_range_str).execute()\n",
    "    values = result.get('values', [])\n",
    "    return values\n",
    "\n",
    "def fetch_primers_data():\n",
    "    return primer_masterlist_sheet2df(PRIMERS_SHEETNAME, 'A1:K', 'CO#')\n",
    "\n",
    "\n",
    "def fetch_primer_mixes_data():\n",
    "    primer_mixes_df = primer_masterlist_sheet2df(PRIMER_MIXES_SHEETNAME,\n",
    "                                                 'A1:O',\n",
    "                                                 'GRNA REC_ID').dropna(how='all')\n",
    "    return primer_mixes_df\n",
    "\n",
    "def get_creds():\n",
    "    creds = None\n",
    "    # The file token.pickle stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('../token.pickle'):\n",
    "        with open('../token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)#/Users/chris.johnson/.config/gcloud/application_default_credentials.json\n",
    "            creds = flow.run_local_server()\n",
    "        # Save the credentials for the next run\n",
    "        with open('../token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    return creds\n",
    "\n",
    "def primer_masterlist_sheet2df(sheetname, data_range, index_name):\n",
    "    data = fetch_data(PRIMER_MASTERLIST_SPREADSHEET_ID, sheetname, data_range)\n",
    "    df = pd.DataFrame.from_records(data[1:], columns=data[0], index=index_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test by REC-ID to see if guides in the picklist are in the primer master list gSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing 0 gRNA REC_IDs in Primer masterlist gSheet\n"
     ]
    }
   ],
   "source": [
    "# Identify any missing REC_IDs\n",
    "selected_primer_mixes_df = fetch_primer_mixes_data()\n",
    "available_gRNA = set(selected_primer_mixes_df.index)\n",
    "\n",
    "missing_REC_IDs = set()\n",
    "for experiment in experiments:\n",
    "    picklist = experiments[experiment]['picklist']\n",
    "    gRNAs = set(picklist['REC ID'])\n",
    "    not_there = gRNAs.difference(available_gRNA)\n",
    "    missing_REC_IDs = (missing_REC_IDs | not_there)\n",
    "print('missing',len(missing_REC_IDs),'gRNA REC_IDs in Primer masterlist gSheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This reports any gRNA REC-IDs not found in Sarah's sheet.\n",
    "# If any are reported, they need to be resolved before proceeding\n",
    "missing_REC_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run genotyping picklist maker\n",
    "use the make_picklist function imported from Genoytping_picklist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wish to use only certain plates for primer mixes (mix_plates) or sequencing primers (seq_plates)\n",
    "# definee that here\n",
    "mix_plates = '26,27,28,29'\n",
    "seq_plates = '44,45'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment IB-GP-E3-H-B1_IB-PG-E1-H-B3_guide\n",
      "Plate IB-GP-E3-H-B1_IB-PG-E1-H-B3 P-1\n",
      "Quad Q1\n",
      "Quad Q2\n",
      "Quad Q3\n",
      "Quad Q4\n",
      "Experiment IB-GP-E3-H-B2_IB-GP-E2-H-B3_guide\n",
      "Plate IB-GP-E3-H-B2_IB-GP-E2-H-B3 P-1\n",
      "Quad Q1\n",
      "Quad Q2\n",
      "Quad Q3\n",
      "Quad Q4\n",
      "Experiment IB-GP-E3-H-B3_guide\n",
      "Plate IB-GP-E3-H-B3 P-1\n",
      "Quad Q1\n",
      "Quad Q3\n"
     ]
    }
   ],
   "source": [
    "# Run the picklist making function for each quad in each plate in each experiment\n",
    "# Verbose output so if an error happens it may be possible to see where\n",
    "for experiment in experiments:\n",
    "    print('Experiment',experiment)\n",
    "    directory = experiments[experiment]['directory']\n",
    "    for plate in experiments[experiment]['plates']:\n",
    "        print('Plate',plate)\n",
    "        PCR_picklists = []\n",
    "        seq_picklists = []\n",
    "        map_file = os.path.join(directory,plate+'_map.xlsx')\n",
    "        for quad in experiments[experiment]['plates'][plate]['quad_maps']:\n",
    "            print('Quad',quad)\n",
    "            # make_picklist(map_file, quad) # Use any and all primer plates\n",
    "            make_picklist(map_file, quad, mix_plates=mix_plates, seq_plates=seq_plates) # Use specific primer plates\n",
    "            base_name = '.'.join(map_file.split('.')[:-1])\n",
    "            PCR_picklists.append(f'{base_name}_{quad}{PCR_suffix}')\n",
    "            seq_picklists.append(f'{base_name}_{quad}{seq_suffix}')\n",
    "        experiments[experiment]['plates'][plate]['PCR picklists'] = PCR_picklists\n",
    "        experiments[experiment]['plates'][plate]['seq picklists'] = seq_picklists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File handling, list making after using scripts to make Hamilton picklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to combine hamilton picklists and create name files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_locations(df_in, sfx):\n",
    "    # incoming DF should have columns 'Labware_ID' and 'Dest_ID' -will update certain entries with quadrant number\n",
    "    df = df_in.copy()\n",
    "    sfx = str(sfx)\n",
    "    columns = df.columns.tolist()\n",
    "    labware = columns.index('Labware_ID')\n",
    "    destination = columns.index('Dest_ID')\n",
    "    for i in range(len(df)):\n",
    "        labware_id = str(df.iloc[i,labware])\n",
    "        dest_id = str(df.iloc[i,destination])\n",
    "        if 'Plate' in labware_id:\n",
    "            df.iloc[i,labware] = 'Plate'+sfx\n",
    "        if 'Destination' in dest_id:\n",
    "            df.iloc[i,destination] = 'Destination'+sfx\n",
    "    return df \n",
    "\n",
    "def concat_picklists(path, picklists):\n",
    "    # General form for reading, updating and concatanating picklists\n",
    "    picklists_all = []\n",
    "    for picklist_file in picklists:\n",
    "        picklist = pd.read_csv(picklist_file)\n",
    "        quad = picklist_file.split('_')[-4][-1] # read quadrant from file name\n",
    "        picklists_all.append(update_locations(picklist, quad))\n",
    "    return pd.concat(picklists_all)\n",
    "\n",
    "def combine_picklists(PCR_picklist, seq_picklist):\n",
    "    # combines info from the PCR picklist and seq picklist\n",
    "    REC_ID_df = PCR_picklist[PCR_picklist['Source_plate'] != PCR_picklist['Source_plate']].copy()\n",
    "    PM_df = PCR_picklist[PCR_picklist['Source_plate'] == PCR_picklist['Source_plate']].copy()\n",
    "    REC_ID_df.set_index(['Dest_ID','Dest_Pos'], inplace = True)\n",
    "    PM_df.set_index(['Dest_ID','Dest_Pos'], inplace = True)\n",
    "    \n",
    "    drop_cols = ['Position', 'Labware_ID', 'Source_plate']\n",
    "    PM_df = PM_df.drop(columns = drop_cols)\n",
    "    REC_ID_df = REC_ID_df.drop(columns = drop_cols)\n",
    "    PM_df.rename(columns = {'Additional_information':'Primer_Mix'}, inplace = True)\n",
    "    REC_ID_df.rename(columns = {'Additional_information':'REC_ID'}, inplace = True)\n",
    "    seq_df = pd.merge(PM_df, REC_ID_df, left_index = True, right_index = True)\n",
    "    \n",
    "    seq_picklist = seq_picklist.set_index(['Dest_ID','Dest_Pos']).copy()\n",
    "    seq_picklist = seq_picklist[['sequencing_primer']]\n",
    "    \n",
    "    return pd.merge(seq_df, seq_picklist, left_index = True, right_index = True)\n",
    "\n",
    "def add_genes(seq_df, REC_IDS, SEQUENCES):\n",
    "    # looks up information of REC_IDs in cauldron\n",
    "    temp = seq_df.copy()\n",
    "    ids = temp['REC_ID'].unique().tolist()\n",
    "    genes = []\n",
    "    sequences = []\n",
    "    for ID in ids: # Add things that aren't in the dicts yet\n",
    "        if ID not in REC_IDS:\n",
    "            x = [i for i in api.guides.find(rec_ids = ID)][0]\n",
    "            REC_IDS[ID] = x['gene']\n",
    "            SEQUENCES[ID] = x['target_sequence']\n",
    "\n",
    "    rec_idx = temp.columns.tolist().index('REC_ID')\n",
    "    for i in range(len(temp)):\n",
    "        rec_id = seq_df.iloc[i, rec_idx]\n",
    "        genes.append(REC_IDS[rec_id])\n",
    "        sequences.append(SEQUENCES[rec_id])\n",
    "    temp['Gene'] = genes\n",
    "    temp['gRNA_Sequence'] = sequences\n",
    "    return temp, REC_IDS, SEQUENCES\n",
    "\n",
    "def add_names(df, exp, plt):\n",
    "    # adds columns with desired naming conventions to df\n",
    "    seq_df = df.copy()\n",
    "    genewiz_names = []\n",
    "    synthego_names = []\n",
    "    control_names = []\n",
    "    for i in range(len(seq_df)):\n",
    "        row = seq_df.iloc[i]\n",
    "        gene = row['Gene']\n",
    "        grna = '-'.join(row['REC_ID'].split('-')[1:])\n",
    "        q = 'Q'+str(row.name[0][-1])\n",
    "        pos = row.name[1]\n",
    "        pm = row['Primer_Mix']\n",
    "        seq_primer = row['sequencing_primer']\n",
    "        genewiz_name = '-'.join([gene,grna,exp,plt,q,pos,pm]) # moved ,pos from before exp to after q\n",
    "        synthego_name = genewiz_name+'-'+seq_primer+'.ab1'\n",
    "        ctrl_expt = exp[:-1]+'0'\n",
    "        control_name = ('-'.join([gene,grna,ctrl_expt,'P0','Q0','WT',pm,seq_primer]))+'.ab1'\n",
    "        genewiz_names.append(genewiz_name)\n",
    "        synthego_names.append(synthego_name)\n",
    "        control_names.append(control_name)\n",
    "    seq_df['Genewiz_name'] = genewiz_names\n",
    "    seq_df['Synthego_name'] = synthego_names\n",
    "    seq_df['Control_name'] = control_names\n",
    "    return seq_df\n",
    "\n",
    "def add_placeholders(seq_df):\n",
    "    # Adds any missing wells as empty rows in the df (assumes 96 well format for all listed plates)\n",
    "    r = list(string.ascii_uppercase)[:8]                       # rows in a full plate\n",
    "    c = [i for i in range(1,13)]                               # columns in a full plate\n",
    "    well = [i+str(n) for n in c for i in r]                    # wells in a full plate\n",
    "    dest = seq_df.index.get_level_values(0).unique().tolist()  # destination plates in the passed df\n",
    "    temp = [[d,w,0] for d in dest for w in well]               # list of all wells in full plates in the passed df\n",
    "    temp_df = pd.DataFrame(temp, columns = ['Dest_ID','Dest_Pos','mock']).set_index(['Dest_ID','Dest_Pos'])\n",
    "    return pd.merge(temp_df,seq_df, left_index = True, right_index = True, how = 'left').drop(columns = ['mock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine picklists and make names\n",
    "This can take a while beccaues of the need to query cauldron in the add_genes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "REC_IDS = {}\n",
    "SEQUENCES = {}\n",
    "for experiment in experiments:\n",
    "    exp_dir = experiments[experiment]['directory']\n",
    "    picklist_dir = os.path.join(exp_dir,'picklists')\n",
    "    if not os.path.isdir(picklist_dir): os.mkdir(picklist_dir)\n",
    "    plates = experiments[experiment]['plates']\n",
    "    for plate in plates:\n",
    "        plt = plate.split(' ')[-1]\n",
    "        PCR_picklist_concat = concat_picklists(exp_dir, plates[plate]['PCR picklists'])\n",
    "        seq_picklist_concat = concat_picklists(exp_dir, plates[plate]['seq picklists'])\n",
    "        seq_name = f'{plate}_map_all{seq_suffix}' \n",
    "        seq_picklist_concat.to_csv(os.path.join(picklist_dir,seq_name), index = False)\n",
    "        PCR_name = f'{plate}_map_all{PCR_suffix}'\n",
    "        PCR_picklist_concat.to_csv(os.path.join(picklist_dir,PCR_name), index = False)\n",
    "        \n",
    "        out_df = combine_picklists(PCR_picklist_concat, seq_picklist_concat)\n",
    "\n",
    "        out_df, REC_IDS, SEQUENCES = add_genes(out_df, REC_IDS, SEQUENCES)\n",
    "        out_df = add_names(out_df, experiment, plt)\n",
    "        out_df = add_placeholders(out_df)\n",
    "        out_name = f'{plate}_sample_names.csv'\n",
    "        out_df.to_csv(os.path.join(picklist_dir,out_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:autoprimer]",
   "language": "python",
   "name": "conda-env-autoprimer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
